{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current working directory: /Users/nilsgandlau/code/browser-automation\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# autoreload any .py scripts\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# set the project's root directory as the notebooks' working directory\n",
    "git_root = subprocess.run(['git', 'rev-parse', '--show-toplevel'], capture_output=True, text=True).stdout.strip()\n",
    "os.chdir(git_root)\n",
    "print(f\"current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "import requests\n",
    "from collections.abc import Callable\n",
    "from typing import Annotated as A, Literal as L\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from annotated_docs.json_schema import as_json_schema  # https://github.com/peterroelants/annotated-docs\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"function\": {\n",
      "    \"name\": \"multiply\",\n",
      "    \"description\": \"\",\n",
      "    \"parameters\": {\n",
      "      \"properties\": {\n",
      "        \"a\": {\n",
      "          \"type\": \"integer\"\n",
      "        },\n",
      "        \"b\": {\n",
      "          \"type\": \"integer\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"a\",\n",
      "        \"b\"\n",
      "      ],\n",
      "      \"type\": \"object\"\n",
      "    }\n",
      "  },\n",
      "  \"type\": \"function\"\n",
      "}\n",
      "{\n",
      "  \"function\": {\n",
      "    \"name\": \"add\",\n",
      "    \"description\": \"\",\n",
      "    \"parameters\": {\n",
      "      \"properties\": {\n",
      "        \"a\": {\n",
      "          \"type\": \"integer\"\n",
      "        },\n",
      "        \"b\": {\n",
      "          \"type\": \"integer\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"a\",\n",
      "        \"b\"\n",
      "      ],\n",
      "      \"type\": \"object\"\n",
      "    }\n",
      "  },\n",
      "  \"type\": \"function\"\n",
      "}\n",
      "{\n",
      "  \"function\": {\n",
      "    \"name\": \"finish\",\n",
      "    \"description\": \"\",\n",
      "    \"parameters\": {\n",
      "      \"properties\": {\n",
      "        \"answer\": {\n",
      "          \"type\": \"string\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"answer\"\n",
      "      ],\n",
      "      \"type\": \"object\"\n",
      "    }\n",
      "  },\n",
      "  \"type\": \"function\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated, Literal\n",
    "\n",
    "class StopException(Exception):\n",
    "    \"\"\"\n",
    "    Stop Execution by raising this exception (Signal that the task is Finished).\n",
    "    \"\"\"\n",
    "\n",
    "def multiply(a: int, b: int) -> str:\n",
    "    return str(a*b)\n",
    "\n",
    "def add(a: int, b: int) -> str:\n",
    "    return str(a+b)\n",
    "\n",
    "def finish(answer: Annotated[str, \"Answer to the user's question.\"]) -> None:\n",
    "    raise StopException(answer)\n",
    "\n",
    "name_to_function_map: dict[str, Callable] = {\n",
    "    \"multiply\": multiply, # idea: replace with `multiply.__name__: multiply` to make this even more programmatically\n",
    "    \"add\": add,\n",
    "    \"finish\": finish\n",
    "}\n",
    "\n",
    "function_schemas = [\n",
    "    {\"function\": as_json_schema(func), \"type\": \"function\"}\n",
    "    for func in name_to_function_map.values()\n",
    "]\n",
    "\n",
    "# Print the JSON Schemas\n",
    "for schema in function_schemas:\n",
    "    print(json.dumps(schema, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "question_prompt = \"Solve the following equation: 1+6*2\"  # solution: 13\n",
    "system_prompt = \"Always respond using a pattern of THOUGHT (reason step-by-step about which function to call next), ACTION (call a function to as a next step towards the final answer), OBSERVATION (output of the function). Reason step by step which actions to take to get to the answer. Only call functions with arguments coming verbatim from the user or the output of other functions.\"\n",
    "#system_prompt = \"Always start your response with: 'here we go:'. Before using a tool, you must provide your THOUGHTS or REASONING.\"\n",
    "system_prompt = \"Always respond using a pattern of THOUGHT (reason step-by-step about which function to call next), ACTION (call a function to as a next step towards the final answer), OBSERVATION (output of the function).\"\n",
    "\n",
    "messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "messages.append({\"role\": \"user\", \"content\": question_prompt})\n",
    "\n",
    "def run(messages: list[dict]) -> list[dict]:\n",
    "    max_iterations = 5\n",
    "    for i in range(max_iterations):\n",
    "        print(f\"--- Iteration {i=} ---\")\n",
    "        # send list of messages to get next response\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "            tools=function_schemas,\n",
    "            tool_choice=\"auto\",\n",
    "        )\n",
    "        response_message = response.choices[0].message\n",
    "        print(response_message)\n",
    "        messages.append(response_message)\n",
    "        # check if GPT wanted to call a function\n",
    "        tool_calls = response_message.tool_calls\n",
    "        if tool_calls:\n",
    "            for tool_call in tool_calls:\n",
    "                function_name = tool_call.function.name\n",
    "                # Validate function name\n",
    "                if function_name not in name_to_function_map:\n",
    "                    print(f\"Invalid function name: {function_name}\")\n",
    "                    messages.append({\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"role\": \"tool\",\n",
    "                        \"name\": function_name,\n",
    "                        \"content\": f\"Invalid function name: {function_name!r}\"\n",
    "                    })\n",
    "                    continue\n",
    "                # Get the function to call\n",
    "                function_to_call: Callable = name_to_function_map[function_name]\n",
    "                # Try getting the function arguments\n",
    "                try:\n",
    "                    function_args_dict = json.loads(tool_call.function.arguments)\n",
    "                except json.JSONDecodeError as exc:\n",
    "                    # JSON decoding failed\n",
    "                    print(f\"Error decoding function arguments: {exc}\")\n",
    "                    messages.append({\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"role\": \"tool\",\n",
    "                        \"name\": function_name, \n",
    "                        \"content\": f\"Error decoding function call `{function_name}` arguments {tool_call.function.arguments!r}! Error: {exc!s}\",\n",
    "                    })\n",
    "                    continue\n",
    "                # Call the selected function with generated arguments\n",
    "                try:\n",
    "                    print(f\"Calling function {function_name} with args: {json.dumps(function_args_dict)}\")\n",
    "                    function_response = function_to_call(**function_args_dict)\n",
    "                    # Extend conversation with function response\n",
    "                    messages.append({\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"role\": \"tool\",\n",
    "                        \"name\": function_name,\n",
    "                        \"content\": function_response,\n",
    "                    })\n",
    "                except StopException as exc:\n",
    "                    # Agent wants to stop the conversation (expected)\n",
    "                    print(f\"Finish task with message: '{exc!s}'\")\n",
    "                    return messages\n",
    "                except Exception as exc:\n",
    "                    # Unexpected error calling the function\n",
    "                    print(f\"Error calling function `{function_name}`: {type(exc).__name__}: {exc!s}\")\n",
    "                    messages.append({\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"role\": \"tool\",\n",
    "                        \"name\": function_name,\n",
    "                        \"content\": f\"Error calling function `{function_name}`: {type(exc).__name__}: {exc!s}\",\n",
    "                    })\n",
    "                    continue\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration i=0 ---\n",
      "ChatCompletionMessage(content='THOUGHT: According to the order of operations (PEMDAS/BODMAS), I need to perform the multiplication first and then the addition.\\n\\n1. Calculate \\\\(6 * 2\\\\)\\n2. Add 1 to the result of step 1\\n\\nACTION: Call the multiply function to calculate \\\\(6 * 2\\\\)', role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Rlnz3cAg4xGpHAydArKJ1jEV', function=Function(arguments='{\"a\":6,\"b\":2}', name='multiply'), type='function')])\n",
      "Calling function multiply with args: {\"a\": 6, \"b\": 2}\n",
      "--- Iteration i=1 ---\n",
      "ChatCompletionMessage(content='THOUGHT: Now that I have the multiplication result (12), I need to add 1 to it.\\n\\nACTION: Call the add function to calculate \\\\(1 + 12\\\\)', role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_gZsDgrPOaM4ICSQsmAF1NGvW', function=Function(arguments='{\"a\":1,\"b\":12}', name='add'), type='function')])\n",
      "Calling function add with args: {\"a\": 1, \"b\": 12}\n",
      "--- Iteration i=2 ---\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_gitSqHHuzVZiqTBagQ1OJApu', function=Function(arguments='{\"answer\":\"13\"}', name='finish'), type='function')])\n",
      "Calling function finish with args: {\"answer\": \"13\"}\n",
      "Finish task with message: '13'\n"
     ]
    }
   ],
   "source": [
    "messages = run(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(len(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'Always respond using a pattern of THOUGHT (reason step-by-step about which function to call next), ACTION (call a function to as a next step towards the final answer), OBSERVATION (output of the function).'},\n",
       " {'role': 'user', 'content': 'Solve the following equation: 1+6*2'},\n",
       " ChatCompletionMessage(content='THOUGHT: According to the order of operations (PEMDAS/BODMAS), I need to perform the multiplication first and then the addition.\\n\\n1. Calculate \\\\(6 * 2\\\\)\\n2. Add 1 to the result of step 1\\n\\nACTION: Call the multiply function to calculate \\\\(6 * 2\\\\)', role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Rlnz3cAg4xGpHAydArKJ1jEV', function=Function(arguments='{\"a\":6,\"b\":2}', name='multiply'), type='function')]),\n",
       " {'tool_call_id': 'call_Rlnz3cAg4xGpHAydArKJ1jEV',\n",
       "  'role': 'tool',\n",
       "  'name': 'multiply',\n",
       "  'content': '12'},\n",
       " ChatCompletionMessage(content='THOUGHT: Now that I have the multiplication result (12), I need to add 1 to it.\\n\\nACTION: Call the add function to calculate \\\\(1 + 12\\\\)', role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_gZsDgrPOaM4ICSQsmAF1NGvW', function=Function(arguments='{\"a\":1,\"b\":12}', name='add'), type='function')]),\n",
       " {'tool_call_id': 'call_gZsDgrPOaM4ICSQsmAF1NGvW',\n",
       "  'role': 'tool',\n",
       "  'name': 'add',\n",
       "  'content': '13'},\n",
       " ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_gitSqHHuzVZiqTBagQ1OJApu', function=Function(arguments='{\"answer\":\"13\"}', name='finish'), type='function')])]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msystem: Always respond using a pattern of THOUGHT (reason step-by-step about which function to call next), ACTION (call a function to as a next step towards the final answer), OBSERVATION (output of the function). Reason step by step which actions to take to get to the answer. Only call functions with arguments coming verbatim from the user or the output of other functions.\n",
      "\u001b[0m\n",
      "\u001b[32muser: Solve the following equation: 1+6*2\n",
      "\u001b[0m\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_MxH5FQuU75z9kkWSgxiT19lU', function=Function(arguments='{\"a\":6,\"b\":2}', name='multiply'), type='function')])\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_wzHmiwj8iN0l4zZuHTIlNWbJ', function=Function(arguments='{\"a\":1,\"b\":12}', name='add'), type='function')])\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_lL6b8Rw0UyY3EaGtTShmkEmS', function=Function(arguments='{\"answer\":\"13\"}', name='finish'), type='function')])\n"
     ]
    }
   ],
   "source": [
    "from termcolor import colored  \n",
    "\n",
    "def pretty_print_conversation(messages):\n",
    "    role_to_color = {\n",
    "        \"system\": \"red\",\n",
    "        \"user\": \"green\",\n",
    "        \"assistant\": \"blue\",\n",
    "        \"function\": \"magenta\",\n",
    "    }\n",
    "    \n",
    "    for message in messages:\n",
    "        if isinstance(message, dict):\n",
    "            if message[\"role\"] == \"system\":\n",
    "                print(colored(f\"system: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "            elif message[\"role\"] == \"user\":\n",
    "                print(colored(f\"user: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "            elif message[\"role\"] == \"assistant\" and message.get(\"function_call\"):\n",
    "                print(colored(f\"assistant: {message['function_call']}\\n\", role_to_color[message[\"role\"]]))\n",
    "            elif message[\"role\"] == \"assistant\" and not message.get(\"function_call\"):\n",
    "                print(colored(f\"assistant: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "            elif message[\"role\"] == \"function\":\n",
    "                print(colored(f\"function ({message['name']}): {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        else:\n",
    "            # message is a function/tool call!\n",
    "            print(message)\n",
    "\n",
    "pretty_print_conversation(messages)\n",
    "\n",
    "# for message in messages:\n",
    "#     if not isinstance(message, dict):\n",
    "#         message = message.model_dump()  # Pydantic model\n",
    "#     print(json.dumps(message, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI ChatCompletion with tools + images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-9bTXZuw0tzIfHt1VEqiJ4jN2FQsbV', 'object': 'chat.completion', 'created': 1718718717, 'model': 'gpt-4o-2024-05-13', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': \"To evaluate the expression \\\\(1 + 6 \\\\times 2\\\\), we need to follow the order of operations (PEMDAS/BODMAS):\\n\\n1. First, perform the multiplication:\\n\\\\[ 6 \\\\times 2 = 12 \\\\]\\n\\n2. Then, perform the addition:\\n\\\\[ 1 + 12 \\\\]\\n\\nI'll calculate the final addition.\", 'function_call': {'name': 'add', 'arguments': '{\\n  \"a\": 1,\\n  \"b\": 12\\n}'}}, 'logprobs': None, 'finish_reason': 'function_call'}], 'usage': {'prompt_tokens': 124, 'completion_tokens': 95, 'total_tokens': 219}, 'system_fingerprint': 'fp_f4e629d0a5'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "api_key = openai_api_key\n",
    "endpoint = 'https://api.openai.com/v1/chat/completions'\n",
    "\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {api_key}',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"model\": \"gpt-4o\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant. You have access to the following tools: multiply, add.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is 1+6*2?\"},\n",
    "    ],\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"multiply\",\n",
    "            \"description\": \"Use this to multiply two numbers.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"a\": {\"type\": \"number\", \"description\": \"First number to be multiplied.\"},\n",
    "                    \"b\": {\"type\": \"number\", \"description\": \"Second number to be multiplied\"}\n",
    "                },\n",
    "                \"required\": [\"a\", \"b\"]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"add\",\n",
    "            \"description\": \"Use this to add two numbers.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"a\": {\"type\": \"number\", \"description\": \"First number to be added.\"},\n",
    "                    \"b\": {\"type\": \"number\", \"description\": \"Second number to be added\"}\n",
    "                },\n",
    "                \"required\": [\"a\", \"b\"]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "response = requests.post(endpoint, headers=headers, data=json.dumps(data))\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To evaluate the expression \\(1 + 6 \\times 2\\), we need to follow the order of operations (PEMDAS/BODMAS):\n",
      "\n",
      "1. First, perform the multiplication:\n",
      "\\[ 6 \\times 2 = 12 \\]\n",
      "\n",
      "2. Then, perform the addition:\n",
      "\\[ 1 + 12 \\]\n",
      "\n",
      "I'll calculate the final addition.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-9bTXZuw0tzIfHt1VEqiJ4jN2FQsbV',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1718718717,\n",
       " 'model': 'gpt-4o-2024-05-13',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': \"To evaluate the expression \\\\(1 + 6 \\\\times 2\\\\), we need to follow the order of operations (PEMDAS/BODMAS):\\n\\n1. First, perform the multiplication:\\n\\\\[ 6 \\\\times 2 = 12 \\\\]\\n\\n2. Then, perform the addition:\\n\\\\[ 1 + 12 \\\\]\\n\\nI'll calculate the final addition.\",\n",
       "    'function_call': {'name': 'add',\n",
       "     'arguments': '{\\n  \"a\": 1,\\n  \"b\": 12\\n}'}},\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'function_call'}],\n",
       " 'usage': {'prompt_tokens': 124, 'completion_tokens': 95, 'total_tokens': 219},\n",
       " 'system_fingerprint': 'fp_f4e629d0a5'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = response.json()\n",
    "print(result[\"choices\"][0][\"message\"][\"content\"])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Assistant API with Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q: Can I get OpenAI Assistant API to call a function \n",
    "# `extract_data_from_image()` after it sees an image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload image to OpenAI\n",
    "file = client.files.create(\n",
    "    file=open(\"screenshots/79.jpg\", \"rb\"),\n",
    "    purpose=\"vision\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "  name=\"Image Describer\",\n",
    "  description=\"You are great at describing images.\",\n",
    "  model=\"gpt-4o\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_Aa1ggTLpJrHbWSCNbnLeEkLM', created_at=1718724836, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=ToolResourcesCodeInterpreter(file_ids=['file-7BHa88wkH1ikNWOOM7TJIxKt']), file_search=None))\n",
      "Run(id='run_9wbRQZzqE2BpB1xyvNTGNjmD', assistant_id='asst_qlDE9IWhi6tuDzdVQWUnHCLM', cancelled_at=None, completed_at=None, created_at=1718724837, expires_at=1718725437, failed_at=None, incomplete_details=None, instructions=None, last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-4o', object='thread.run', parallel_tool_calls=True, required_action=None, response_format='auto', started_at=None, status='queued', thread_id='thread_Aa1ggTLpJrHbWSCNbnLeEkLM', tool_choice='auto', tools=[], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=None, temperature=1.0, top_p=1.0, tool_resources={})\n",
      "SyncCursorPage[Message](data=[], object='list', first_id=None, last_id=None, has_more=False)\n"
     ]
    }
   ],
   "source": [
    "thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Describe what you see in the image.\",\n",
    "            \"attachments\": [\n",
    "                {\n",
    "                    \"file_id\": file.id,\n",
    "                    \"tools\": [{\"type\": \"code_interpreter\"}]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id\n",
    ")\n",
    "# wait ... status can be 'queued'!\n",
    "messages = client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id)\n",
    "print(thread)\n",
    "print(run)\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations: []\n",
      "Message: I cannot view the image you uploaded due to current limitations. Could you please provide a description or any details about the image? This would help me assist you better.\n"
     ]
    }
   ],
   "source": [
    "messages = client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id)\n",
    "print(f\"Annotations: {messages.data[0].content[0].text.annotations}\")\n",
    "print(f\"Message: {messages.data[0].content[0].text.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_rcH2oiwkEGHq3fKEVLc63b2t', created_at=1718724934, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))\n",
      "Run(id='run_Spyev72UCh7D6SYv9QG5qi3w', assistant_id='asst_qlDE9IWhi6tuDzdVQWUnHCLM', cancelled_at=None, completed_at=None, created_at=1718724934, expires_at=1718725534, failed_at=None, incomplete_details=None, instructions=None, last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-4o', object='thread.run', parallel_tool_calls=True, required_action=None, response_format='auto', started_at=None, status='queued', thread_id='thread_rcH2oiwkEGHq3fKEVLc63b2t', tool_choice='auto', tools=[], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=None, temperature=1.0, top_p=1.0, tool_resources={})\n",
      "SyncCursorPage[Message](data=[], object='list', first_id=None, last_id=None, has_more=False)\n"
     ]
    }
   ],
   "source": [
    "# alternative\n",
    "thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"Describe what you see in the image.\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_file\",\n",
    "          \"image_file\": {\"file_id\": file.id}\n",
    "        },\n",
    "      ],\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id\n",
    ")\n",
    "# wait ... status can be 'queued'!\n",
    "messages = client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id)\n",
    "print(thread)\n",
    "print(run)\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations: []\n",
      "Message: The image depicts a booking schedule for tennis courts, specifically for Friday, June 14, 2024. The schedule is laid out in a grid format, with time slots listed vertically along the left side, starting at 10:00 and ending at 21:30 in 30-minute increments. Horizontally along the top, there are labels for different courts or places (Platz 1 through Platz 10 and Ballwand Zeit).\n",
      "\n",
      "Each cell in the grid represents a 30-minute time slot for a specific court. The cells are color-coded:\n",
      "- Red cells are likely indicating that the time slot is already booked.\n",
      "- Blue cells with the word \"BUCHEN\" (German for \"book\") indicate that these time slots are available for booking.\n",
      "\n",
      "The page header includes options such as \"Startseite\" (home page), \"Camps,\" \"Events & Kurse\" (events and courses), \"Tennis Halle\" (tennis hall), \"Guthaben & Gutscheine\" (credits and vouchers), \"Login,\" and \"Registrieren\" (register).\n",
      "\n",
      "At the bottom, there are various icons and links including \"Open in eigener Webseide\" (open on own website), \"eBuSy\" branding, and other navigation and information tools typically found on a booking or scheduling website.\n"
     ]
    }
   ],
   "source": [
    "messages = client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id)\n",
    "print(f\"Annotations: {messages.data[0].content[0].text.annotations}\")\n",
    "print(f\"Message: {messages.data[0].content[0].text.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assistant function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_lOXX3gklVAHcxdrLdtruY5oI', created_at=1718726422, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))\n",
      "Run(id='run_NIkIyWEGxmrpauHQg1r38QCM', assistant_id='asst_H6b2d5WKJQBJAYRKKKycTzgt', cancelled_at=None, completed_at=None, created_at=1718726423, expires_at=1718727023, failed_at=None, incomplete_details=None, instructions='You are a weather bot. Use provided functions to answer questions.', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-4o', object='thread.run', parallel_tool_calls=True, required_action=RequiredAction(submit_tool_outputs=RequiredActionSubmitToolOutputs(tool_calls=[RequiredActionFunctionToolCall(id='call_xOrsZWPXjl9qSfoJojRGjN7b', function=Function(arguments='{\"location\": \"Frankfurt, Germany\", \"unit\": \"Celsius\"}', name='get_current_temperature'), type='function'), RequiredActionFunctionToolCall(id='call_K8ndyNHA0rp0SKcBIOm3h8Nm', function=Function(arguments='{\"location\": \"Frankfurt, Germany\"}', name='get_rain_probability'), type='function')]), type='submit_tool_outputs'), response_format='auto', started_at=1718726423, status='requires_action', thread_id='thread_lOXX3gklVAHcxdrLdtruY5oI', tool_choice='auto', tools=[FunctionTool(function=FunctionDefinition(name='get_current_temperature', description='Get the current temperature for a specific location', parameters={'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The city and state, e.g., San Francisco, CA'}, 'unit': {'type': 'string', 'enum': ['Celsius', 'Fahrenheit'], 'description': \"The temperature unit to use. Infer this from the user's location.\"}}, 'required': ['location', 'unit']}), type='function'), FunctionTool(function=FunctionDefinition(name='get_rain_probability', description='Get the probability of rain for a specific location', parameters={'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The city and state, e.g., San Francisco, CA'}}, 'required': ['location']}), type='function')], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=None, temperature=1.0, top_p=1.0, tool_resources={})\n",
      "SyncCursorPage[Message](data=[], object='list', first_id=None, last_id=None, has_more=False)\n"
     ]
    }
   ],
   "source": [
    "get_current_temperature_json = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_current_temperature\",\n",
    "        \"description\": \"Get the current temperature for a specific location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city and state, e.g., San Francisco, CA\"\n",
    "            },\n",
    "            \"unit\": {\n",
    "                \"type\": \"string\",\n",
    "                \"enum\": [\"Celsius\", \"Fahrenheit\"],\n",
    "                \"description\": \"The temperature unit to use. Infer this from the user's location.\"\n",
    "            }\n",
    "            },\n",
    "            \"required\": [\"location\", \"unit\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "get_rain_probability_json = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_rain_probability\",\n",
    "        \"description\": \"Get the probability of rain for a specific location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city and state, e.g., San Francisco, CA\"\n",
    "            }\n",
    "            },\n",
    "            \"required\": [\"location\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    instructions=\"You are a weather bot. Use provided functions to answer questions.\",\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[get_current_temperature_json, get_rain_probability_json]\n",
    ")\n",
    "thread = client.beta.threads.create()\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"what is the weather in frankfurt, germany?\"\n",
    ")\n",
    "\n",
    "#! This does not work:\n",
    "# run = client.beta.threads.runs.create(\n",
    "    # thread_id=thread.id,\n",
    "    # assistant_id=assistant.id\n",
    "# )\n",
    "\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    ")\n",
    "\n",
    "# wait ... status can be 'queued'!\n",
    "messages = client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id)\n",
    "print(thread)\n",
    "print(run)\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'requires_action'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if a function is called, the status of the `run` changes to `\"requires_action\"`\n",
    "run.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RequiredAction(submit_tool_outputs=RequiredActionSubmitToolOutputs(tool_calls=[RequiredActionFunctionToolCall(id='call_xOrsZWPXjl9qSfoJojRGjN7b', function=Function(arguments='{\"location\": \"Frankfurt, Germany\", \"unit\": \"Celsius\"}', name='get_current_temperature'), type='function'), RequiredActionFunctionToolCall(id='call_K8ndyNHA0rp0SKcBIOm3h8Nm', function=Function(arguments='{\"location\": \"Frankfurt, Germany\"}', name='get_rain_probability'), type='function')]), type='submit_tool_outputs')\n",
      "\n",
      "[RequiredActionFunctionToolCall(id='call_xOrsZWPXjl9qSfoJojRGjN7b', function=Function(arguments='{\"location\": \"Frankfurt, Germany\", \"unit\": \"Celsius\"}', name='get_current_temperature'), type='function'), RequiredActionFunctionToolCall(id='call_K8ndyNHA0rp0SKcBIOm3h8Nm', function=Function(arguments='{\"location\": \"Frankfurt, Germany\"}', name='get_rain_probability'), type='function')]\n",
      "\n",
      "GPT wants to call the following function: \n",
      "\t* tool name: get_current_temperature\n",
      "\t* tool args: {\"location\": \"Frankfurt, Germany\", \"unit\": \"Celsius\"}\n",
      "GPT wants to call the following function: \n",
      "\t* tool name: get_rain_probability\n",
      "\t* tool args: {\"location\": \"Frankfurt, Germany\"}\n"
     ]
    }
   ],
   "source": [
    "# In that case, GPT wants to call a certain function with certain arguments.\n",
    "print(run.required_action)\n",
    "print()\n",
    "print(run.required_action.submit_tool_outputs.tool_calls)\n",
    "print()\n",
    "\n",
    "for tool in run.required_action.submit_tool_outputs.tool_calls:\n",
    "    print(\"GPT wants to call the following function: \")\n",
    "    print(f\"\\t* tool name: {tool.function.name}\")\n",
    "    print(f\"\\t* tool args: {tool.function.arguments}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool outputs submitted successfully.\n"
     ]
    }
   ],
   "source": [
    "# simulate function responses:\n",
    "tool_outputs = []\n",
    "for tool in run.required_action.submit_tool_outputs.tool_calls:\n",
    "    if tool.function.name == \"get_current_temperature\":\n",
    "        tool_outputs.append({\"tool_call_id\": tool.id, \"output\": \"30°C\"})\n",
    "    if tool.function.name == \"get_rain_probability\":\n",
    "        tool_outputs.append({\"tool_call_id\": tool.id, \"output\": \"80%\"})\n",
    "\n",
    "# submit all tool outputs\n",
    "if tool_outputs:\n",
    "  try:\n",
    "    run = client.beta.threads.runs.submit_tool_outputs_and_poll(\n",
    "      thread_id=thread.id,\n",
    "      run_id=run.id,\n",
    "      tool_outputs=tool_outputs\n",
    "    )\n",
    "    print(\"Tool outputs submitted successfully.\")\n",
    "  except Exception as e:\n",
    "    print(\"Failed to submit tool outputs:\", e)\n",
    "else:\n",
    "  print(\"No tool outputs to submit.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[Message](data=[Message(id='msg_x1Re2LPGRtT1XOk2G7s7rNHu', assistant_id='asst_H6b2d5WKJQBJAYRKKKycTzgt', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='The current temperature in Frankfurt, Germany is 30°C, with a 80% probability of rain.'), type='text')], created_at=1718726432, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_NIkIyWEGxmrpauHQg1r38QCM', status=None, thread_id='thread_lOXX3gklVAHcxdrLdtruY5oI'), Message(id='msg_AysOabRRcvPwTXahQzr5PyBB', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='what is the weather in frankfurt, germany?'), type='text')], created_at=1718726422, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_lOXX3gklVAHcxdrLdtruY5oI')], object='list', first_id='msg_x1Re2LPGRtT1XOk2G7s7rNHu', last_id='msg_AysOabRRcvPwTXahQzr5PyBB', has_more=False)\n",
      "\n",
      "The current temperature in Frankfurt, Germany is 30°C, with a 80% probability of rain.\n"
     ]
    }
   ],
   "source": [
    "if run.status == 'completed':\n",
    "  messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id\n",
    "  )\n",
    "  print(messages)\n",
    "  print()\n",
    "  print(messages.data[0].content[0].text.value)\n",
    "else:\n",
    "  print(run.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make the agent more verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    instructions=\"Always respond using a pattern of THOUGHT (reason step-by-step about which function to call next), ACTION (call a function to as a next step towards the final answer), OBSERVATION (output of the function).\",\n",
    "    # instructions=\"You are a researcher that thinks step-by-step before every response. If you use a function, explain your reasoning. You must repeat back the function output verbatim when answering, without alterations.\",\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[get_current_temperature_json, get_rain_probability_json]\n",
    ")\n",
    "thread = client.beta.threads.create()\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"what is the weather in frankfurt, germany?\"\n",
    ")\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool outputs submitted successfully.\n"
     ]
    }
   ],
   "source": [
    "# simulate function responses:\n",
    "tool_outputs = []\n",
    "for tool in run.required_action.submit_tool_outputs.tool_calls:\n",
    "    if tool.function.name == \"get_current_temperature\":\n",
    "        tool_outputs.append({\"tool_call_id\": tool.id, \"output\": \"couldnt get the temperature!\"})\n",
    "    if tool.function.name == \"get_rain_probability\":\n",
    "        tool_outputs.append({\"tool_call_id\": tool.id, \"output\": \"80%\"})\n",
    "\n",
    "# submit all tool outputs\n",
    "if tool_outputs:\n",
    "  try:\n",
    "    run = client.beta.threads.runs.submit_tool_outputs_and_poll(\n",
    "      thread_id=thread.id,\n",
    "      run_id=run.id,\n",
    "      tool_outputs=tool_outputs\n",
    "    )\n",
    "    print(\"Tool outputs submitted successfully.\")\n",
    "  except Exception as e:\n",
    "    print(\"Failed to submit tool outputs:\", e)\n",
    "else:\n",
    "  print(\"No tool outputs to submit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[Message](data=[Message(id='msg_Vtit6kUQJ9BAxMqcHhIuQLQz', assistant_id='asst_XZckIsxT3vcUlp2rlk0BHEGq', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value=\"It looks like I couldn't retrieve the current temperature for Frankfurt, Germany. However, the probability of rain there is 80%.\"), type='text')], created_at=1718742908, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_pIQ8UUeSmoCu4o6USLAExNu5', status=None, thread_id='thread_INYhVPRoWaaVdL2GWd6djvTl'), Message(id='msg_bXju9JRwoTPk9RYV6qhRZKQ7', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='what is the weather in frankfurt, germany?'), type='text')], created_at=1718742901, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_INYhVPRoWaaVdL2GWd6djvTl')], object='list', first_id='msg_Vtit6kUQJ9BAxMqcHhIuQLQz', last_id='msg_bXju9JRwoTPk9RYV6qhRZKQ7', has_more=False)\n",
      "\n",
      "\u001b[32mwhat is the weather in frankfurt, germany?\u001b[0m\n",
      "\u001b[31mIt looks like I couldn't retrieve the current temperature for Frankfurt, Germany. However, the probability of rain there is 80%.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "\n",
    "\n",
    "if run.status == 'completed':\n",
    "  messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id\n",
    "  )\n",
    "  print(messages)\n",
    "  print()\n",
    "  print(colored(messages.data[1].content[0].text.value, color=\"green\"))\n",
    "  print(colored(messages.data[0].content[0].text.value, color=\"red\"))\n",
    "else:\n",
    "  print(run.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a researcher that thinks step-by-step before every response. If you use a function, explain your reasoning. Describe the output of the function calls using 'OBSERVATION:' prefix.\n",
      "[FunctionTool(function=FunctionDefinition(name='get_current_temperature', description='Get the current temperature for a specific location', parameters={'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The city and state, e.g., San Francisco, CA'}, 'unit': {'type': 'string', 'enum': ['Celsius', 'Fahrenheit'], 'description': \"The temperature unit to use. Infer this from the user's location.\"}}, 'required': ['location', 'unit']}), type='function'), FunctionTool(function=FunctionDefinition(name='get_rain_probability', description='Get the probability of rain for a specific location', parameters={'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The city and state, e.g., San Francisco, CA'}}, 'required': ['location']}), type='function')]\n",
      "auto\n"
     ]
    }
   ],
   "source": [
    "print(run.instructions)\n",
    "print(run.tools)\n",
    "print(run.tool_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_current_temperature\n",
      "{'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The city and state, e.g., San Francisco, CA'}, 'unit': {'type': 'string', 'enum': ['Celsius', 'Fahrenheit'], 'description': \"The temperature unit to use. Infer this from the user's location.\"}}, 'required': ['location', 'unit']}\n",
      "get_rain_probability\n",
      "{'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The city and state, e.g., San Francisco, CA'}}, 'required': ['location']}\n"
     ]
    }
   ],
   "source": [
    "for tool in run.tools:\n",
    "    print(tool.function.name)\n",
    "    print(tool.function.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.tool_resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[Message](data=[Message(id='msg_OrF4TeGGO4JBXmkCqrPgwpRr', assistant_id='asst_6Y3v0Xgc6ztOPc7UBjulADTI', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='OBSERVATION: \\n1. The current temperature in Frankfurt, Germany is 30°C.\\n2. The probability of rain in Frankfurt, Germany is 80%.\\n\\nSUMMARY: \\nThe temperature in Frankfurt is currently 30°C, and there is an 80% chance of rain.'), type='text')], created_at=1718738598, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_YysAhwZQGeDIgdfeNWKsoDkT', status=None, thread_id='thread_0PBLyh5iCfL00tJC7aQklhvK'), Message(id='msg_YGXHKP4eP1eANb1DmxAWBOJ0', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='what is the weather in frankfurt, germany?'), type='text')], created_at=1718738589, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_0PBLyh5iCfL00tJC7aQklhvK')], object='list', first_id='msg_OrF4TeGGO4JBXmkCqrPgwpRr', last_id='msg_YGXHKP4eP1eANb1DmxAWBOJ0', has_more=False)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
